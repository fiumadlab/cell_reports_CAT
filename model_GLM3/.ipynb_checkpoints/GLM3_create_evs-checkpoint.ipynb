{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model GLM3\n",
    "## Create condition-specific EV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel/__main__.py:41: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel/__main__.py:42: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel/__main__.py:43: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel/__main__.py:44: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/data/madlab/envs/wmaze_madlab_env/lib/python2.7/site-packages/ipykernel/__main__.py:46: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "stim_sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    dir_file = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))  \n",
    "    dir_file.sort() \n",
    "       \n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        for curr_run in ['1','2']:\n",
    "            if curr_run == '1':\n",
    "                run = pd.read_table(dir_file[i*2]) #create dataframe for text files to extract EVS\n",
    "                run = run[:-3] #removal of the last 3 trials to avoid scanner artifact\n",
    "            else:\n",
    "                run = pd.read_table(dir_file[i*2+1])\n",
    "                run = run[:-3]\n",
    "        \n",
    "            trialtype = run['TrialType'].values #convert dataframes into numpy arrays\n",
    "            correct = run['Correct'].values\n",
    "            resp = run['Resp'].values \n",
    "            \n",
    "            trial_shift = trialtype[1:] #shift back and insert dummy (-1) in last index\n",
    "            trial_shift = np.append(trial_shift,-1)\n",
    "            correct_shift = correct[1:]\n",
    "            correct_shift = np.append(correct_shift,-1)       \n",
    "\n",
    "            #grab indices matching multiple specified criteria\n",
    "            fixed_b4_cond_corr = np.where(((trial_shift=='B') & (correct_shift==1)) & (trialtype!='BL'))\n",
    "            fixed_b4_cond_incorr = np.where(((trial_shift=='B') & (correct_shift==0)) & (trialtype!='BL'))\n",
    "            fixed_2A = np.where((trial_shift=='A') & (trialtype=='A') & (resp!='NR'))\n",
    "            fixed_2C = np.where((trial_shift=='C') & (trialtype=='C') & (resp!='NR'))        \n",
    "            fixed_AC = np.where((trial_shift=='C') & (trialtype=='A') & (resp!='NR'))\n",
    "            fixed_CA = np.where((trial_shift=='A') & (trialtype=='C') & (resp!='NR'))       \n",
    "            fixed_lost = np.where(((trialtype=='A') | (trialtype=='C')) & (trial_shift=='BL'))\n",
    "            nonresponse = np.where((resp == 'NR'))\n",
    "       \n",
    "            #remove 156 indices if exists in fixed-fixed arrays                               \n",
    "            run_types = {'fixed_2A': fixed_2A[0], 'fixed_2C': fixed_2C[0], \n",
    "                         'fixed_AC': fixed_AC[0], 'fixed_CA': fixed_CA[0]} \n",
    "        \n",
    "            for key in run_types:\n",
    "                if len(run_types[key]) > 0:\n",
    "                    if run_types[key][-1] == 156:\n",
    "                        run_types[key] = run_types[key][:-1]\n",
    "\n",
    "            onsets = run['StimOnset']\n",
    "             \n",
    "            #onsets for fixed before conditional indices    \n",
    "            fixed_b4_cond_corr_onsets = onsets.values[fixed_b4_cond_corr[0]]\n",
    "            fixed_b4_cond_incorr_onsets = onsets.values[fixed_b4_cond_incorr[0]]\n",
    "            #onsets for separate fixed-same indices\n",
    "            fixed_2A_onsets = onsets.values[(run_types['fixed_2A'],)]\n",
    "            fixed_2C_onsets = onsets.values[(run_types['fixed_2C'],)]\n",
    "            fixed_AC_onsets = onsets.values[(run_types['fixed_AC'],)]\n",
    "            fixed_CA_onsets = onsets.values[(run_types['fixed_CA'],)]\n",
    "            #combine into single sorted array\n",
    "            fixed_same_onsets = sorted(np.append(fixed_2A_onsets,fixed_2C_onsets))\n",
    "            fixed_change_onsets = sorted(np.append(fixed_AC_onsets,fixed_CA_onsets))\n",
    "            fixed_lost_onsets = onsets.values[fixed_lost[0]]\n",
    "            nonresponse_onsets = onsets.values[nonresponse[0]]\n",
    "\n",
    "            #v-stack matrix containing *ALL* onsets, durations, and amplitudes in vertical columns \n",
    "            mtrx = np.vstack((onsets, np.ones(len(onsets))*2.5, #Numpy array filled with 3's\n",
    "                              np.ones(len(onsets)))).T #Numpy array filled with 1's      \n",
    "            fixed_before_cond_corr_mtrx = np.vstack((fixed_b4_cond_corr_onsets, \n",
    "                                                     np.ones(len(fixed_b4_cond_corr_onsets))*2.5,\n",
    "                                                     np.ones(len(fixed_b4_cond_corr_onsets)))).T\n",
    "            \n",
    "            fixed_before_cond_incorr_mtrx = np.vstack((fixed_b4_cond_incorr_onsets, \n",
    "                                                       np.ones(len(fixed_b4_cond_incorr_onsets))*2.5,\n",
    "                                                       np.ones(len(fixed_b4_cond_incorr_onsets)))).T \n",
    "            \n",
    "            fixed_same_mtrx = np.vstack((fixed_same_onsets, np.ones(len(fixed_same_onsets))*2.5,\n",
    "                                         np.ones(len(fixed_same_onsets)))).T     \n",
    "            \n",
    "            fixed_change_mtrx = np.vstack((fixed_change_onsets, np.ones(len(fixed_change_onsets))*2.5,\n",
    "                                           np.ones(len(fixed_change_onsets)))).T  \n",
    "            \n",
    "            fixed_lost_mtrx = np.vstack((fixed_lost_onsets, np.ones(len(fixed_lost_onsets))*2.5,\n",
    "                                         np.ones(len(fixed_lost_onsets)))).T\n",
    "            \n",
    "            nonresponse_mtrx = np.vstack((nonresponse_onsets, np.ones(len(nonresponse_onsets))*2.5,\n",
    "                                          np.ones(len(nonresponse_onsets)))).T\n",
    "                    \n",
    "            if not os.path.exists(join(sub_dir, 'model_GLM3/')): #if directory does not exist\n",
    "                os.makedirs(join(sub_dir, 'model_GLM3/')) #create it\n",
    "\n",
    "            if curr_run == '1': #if the first run in a stimulus set\n",
    "                np.savetxt(sub_dir+'model_GLM3/'+'run{0}.txt'.format(i*2+1),mtrx,delimiter='\\t',fmt='%.4f')                \n",
    "                for trial in ['fixed_before_cond_corr','fixed_before_cond_incorr',\n",
    "                              'fixed_same','fixed_change','fixed_lost', 'nonresponse']: #for all trial types\n",
    "                    exec('np.savetxt(sub_dir+\"model_GLM3/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+1,trial))\n",
    "            else: #if the second run in a stimulus set\n",
    "                np.savetxt(sub_dir+'model_GLM3/'+'run{0}.txt'.format(i*2+2),mtrx,delimiter='\\t',fmt='%.4f')                \n",
    "                for trial in ['fixed_before_cond_corr','fixed_before_cond_incorr',\n",
    "                              'fixed_same','fixed_change','fixed_lost', 'nonresponse']:\n",
    "                    exec('np.savetxt(sub_dir+\"model_GLM3/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+2,trial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model GLM3 Descriptives -- Double Fixed Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from math import sqrt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_003', 'WMAZE_004', 'WMAZE_005',\n",
    "        'WMAZE_006', 'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', \n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "#subs = ['WMAZE_001']\n",
    "stim_sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "count_table = {}\n",
    "ctstd_table = {}\n",
    "rt_table = {}\n",
    "rtstd_table = {}\n",
    "\n",
    "for sub in subs:\n",
    "    ct_dict = {}\n",
    "    rt_dict = {}\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    dir_file = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))    \n",
    "    dir_file.sort() \n",
    "\n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        for curr_run in ['1', '2']:\n",
    "            if curr_run == '1':\n",
    "                run = pd.read_table(dir_file[i * 2]) #create dataframe for text files to extract EVS\n",
    "                run = run[:-3] #removal of the last 3 trials to avoid scanner artifact\n",
    "            else:\n",
    "                run = pd.read_table(dir_file[i * 2 + 1])\n",
    "                run = run[:-3]\n",
    "        \n",
    "            trialtype = run['TrialType'].values\n",
    "            correct = run['Correct'].values\n",
    "            resp = run['Resp'].values \n",
    "\n",
    "            trialtype = run['TrialType'].values #convert dataframes into numpy arrays\n",
    "            correct = run['Correct'].values\n",
    "            resp = run['Resp'].values \n",
    "            \n",
    "            trial_shift = trialtype[1:] #shift back and insert dummy (-1) in last index\n",
    "            trial_shift = np.append(trial_shift,-1)\n",
    "            correct_shift = correct[1:]\n",
    "            correct_shift = np.append(correct_shift,-1)               \n",
    "        \n",
    "            A2_corr = np.where((trial_shift == 'A') & (trialtype == 'A') & (correct_shift == 1))\n",
    "            C2_corr = np.where((trial_shift == 'C') & (trialtype == 'C') & (correct_shift == 1))\n",
    "            AC_corr = np.where((trial_shift == 'C') & (trialtype == 'A') & (correct_shift == 1))\n",
    "            CA_corr = np.where((trial_shift == 'A') & (trialtype == 'C') & (correct_shift == 1))\n",
    "            same_corr = sorted(np.append(A2_corr, C2_corr))\n",
    "            change_corr = sorted(np.append(AC_corr, CA_corr))\n",
    "        \n",
    "            A2_incorr = np.where((trial_shift == 'A') & (trialtype == 'A') & (correct_shift == 0))\n",
    "            C2_incorr = np.where((trial_shift == 'C') & (trialtype == 'C') & (correct_shift == 0))\n",
    "            AC_incorr = np.where((trial_shift == 'C') & (trialtype == 'A') & (correct_shift == 0))\n",
    "            CA_incorr = np.where((trial_shift == 'A') & (trialtype == 'C') & (correct_shift == 0))\n",
    "            same_incorr = sorted(np.append(A2_incorr, C2_incorr))\n",
    "            change_incorr = sorted(np.append(AC_incorr, CA_incorr))\n",
    "        \n",
    "            run_types = {'same_corr': same_corr, 'change_corr': change_corr,\n",
    "                         'same_corr': same_corr, 'change_corr': change_corr,\n",
    "                         'same_incorr': same_incorr, 'change_incorr': change_incorr,\n",
    "                         'same_incorr': same_incorr, 'change_incorr': change_incorr} \n",
    "        \n",
    "            for key in run_types:\n",
    "                if len(run_types[key]) > 0:\n",
    "                    if run_types[key][-1] == 156:\n",
    "                        run_types[key] = run_types[key][:-1]   \n",
    "                    \n",
    "            RTs = run['RT']   \n",
    "         \n",
    "            same_corr_RTs = RTs.values[(run_types['same_corr'],)]\n",
    "            change_corr_RTs = RTs.values[(run_types['change_corr'],)] \n",
    "            same_incorr_RTs = RTs.values[(run_types['same_incorr'],)]\n",
    "            change_incorr_RTs = RTs.values[(run_types['change_incorr'],)]\n",
    "                      \n",
    "            for curr_type in ['same', 'change']:\n",
    "                for acc in ['corr', 'incorr']:\n",
    "                    curr_name = '{0}_{1}'.format(curr_type, acc)\n",
    "                    rt_name = '{0}_{1}_RTs'.format(curr_type, acc)\n",
    "                    if not curr_name in ct_dict:\n",
    "                        ct_dict[curr_name] = []\n",
    "                    ct_dict[curr_name].append(len(eval(curr_name)))\n",
    "                    if not rt_name in rt_dict:\n",
    "                        rt_dict[rt_name] = []\n",
    "                    rt_eval = eval(rt_name)\n",
    "                    rt_notNaN = np.where(rt_eval >= 0)\n",
    "                    rt_notNaN = rt_eval[rt_notNaN[0]]           \n",
    "                    if rt_notNaN.shape[0] == 0:\n",
    "                        rt_dict[rt_name].append(None)                       \n",
    "                    else:\n",
    "                        rt_dict[rt_name].append(np.average(rt_notNaN))\n",
    "                      \n",
    "    for key in ct_dict:\n",
    "        ct_dict[key] = np.sum(ct_dict[key])\n",
    "        if not key in count_table:\n",
    "            count_table[key] = []\n",
    "        count_table[key].append(ct_dict[key])\n",
    "        \n",
    "        \n",
    "    for key in rt_dict:\n",
    "        rt_notNONE = np.where(np.array(rt_dict[key]) >= 0)\n",
    "        rt_dict[key] = np.average(np.array(rt_dict[key])[rt_notNONE[0]])\n",
    "        if not key in rt_table:\n",
    "            rt_table[key] = []\n",
    "        rt_table[key].append(rt_dict[key])\n",
    "\n",
    "        \n",
    "df = pd.DataFrame(count_table, index = subs) \n",
    "df2 = pd.DataFrame(rt_table, index = subs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ct_avg = {}\n",
    "ct_std = {}\n",
    "\n",
    "for curr_key in count_table:\n",
    "    ct_avg[curr_key] = np.average(count_table[curr_key])\n",
    "    ct_std[curr_key] = np.std(count_table[curr_key])\n",
    "    \n",
    "count_average = pd.DataFrame(ct_avg, index = (1,))\n",
    "count_std = pd.DataFrame(ct_std, index = (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM3 Count Average and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM3 Individual Subject Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in ['same_corr', 'same_incorr', 'change_corr', 'change_incorr']:\n",
    "    print '{0} mean'.format(i), np.mean(df['{0}'.format(i)])\n",
    "    print \"\"\n",
    "print 'Paired Sample t-test', stats.ttest_rel(df['same_corr'], df['change_corr'])[:]\n",
    "\n",
    "N = 4\n",
    "conditions = ['Same Correct', 'Same Incorrect', 'Change Correct', 'Change Incorrect']\n",
    "allsubjs = [df['same_corr'], df['same_incorr'], df['change_corr'], df['change_incorr']]  \n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax = sns.boxplot(data = allsubjs, orient='h')\n",
    "ax = sns.swarmplot(data = allsubjs, color='.25', orient='h')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(conditions)\n",
    "ax.set_ylabel(\"Pair Type\")\n",
    "ax.set_xlabel(\"Average # of Trials\")\n",
    "ax.set_title(\"Fixed Pair Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "conditions = ['Same', 'Change']\n",
    "allsubjs2 = [df['same_corr']/(df['same_corr'] + df['same_incorr']), \n",
    "             df['change_corr']/(df['change_corr'] + df['change_incorr'])]  \n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax = sns.boxplot(data = allsubjs2, width = 0.3)\n",
    "ax = sns.swarmplot(data = allsubjs2, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_xlabel(\"Pair Type/Outcome\")\n",
    "ax.set_ylabel(\"Proportion Correct\")\n",
    "ax.set_title(\"Fixed Pair Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_average ={}\n",
    "rt_std = {}\n",
    "\n",
    "for curr_key in rt_table:\n",
    "    rt_average[curr_key] = np.average(rt_table[curr_key])\n",
    "    rt_std[curr_key] = np.average(rt_table[curr_key])\n",
    "    \n",
    "RT_average = pd.DataFrame(rt_average, index = (1,))\n",
    "RT_std = pd.DataFrame(rt_std, index = (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RT_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RT_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"WMAZE Average RT\"\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in ['same_corr', 'same_incorr', 'change_corr', 'change_incorr']:\n",
    "    print '{0} mean'.format(i), np.mean(df2['{0}_RTs'.format(i)])\n",
    "    print \"\"\n",
    "print stats.ttest_rel(df2['same_corr_RTs'], df2['change_corr_RTs'])\n",
    "\n",
    "N = 4\n",
    "conditions = ['Same Correct', 'Same Incorrect', 'Change Correct', 'Change Incorrect']\n",
    "allsubjs = [df2['same_corr_RTs'], df2['same_incorr_RTs'], df2['change_corr_RTs'], df2['change_incorr_RTs']]  \n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "ax = sns.boxplot(data = allsubjs, orient='h')\n",
    "ax = sns.swarmplot(data = allsubjs, color='.25', orient='h')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(conditions)\n",
    "ax.set_ylabel(\"Pair Type\")\n",
    "ax.set_xlabel(\"Average Reaction Time\")\n",
    "ax.set_title(\"Fixed Pair Counts\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
