{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create condition-specific EV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "stim_sets = ['set1', 'set2', 'set3']\n",
    "\n",
    "for sub in subs:\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/scanner_behav/{0}/'.format(sub)\n",
    "    dir_file = glob(join(sub_dir, '{0}_wmazebl_2015*.txt'.format(sub)))   \n",
    "    dir_file.sort() \n",
    " \n",
    "    for i, curr_set in enumerate(stim_sets):\n",
    "        for curr_run in ['1', '2']:\n",
    "            if curr_run == '1':\n",
    "                run = pd.read_table(dir_file[i * 2]) #create dataframe for text files to extract EVS\n",
    "                run = run[:-3] #removal of the last 3 trials to avoid scanner artifact\n",
    "            else:\n",
    "                run = pd.read_table(dir_file[i * 2 + 1])\n",
    "                run = run[:-3]\n",
    "        \n",
    "            trialtype = run['TrialType'].values #convert dataframes into numpy arrays\n",
    "            correct = run['Correct'].values\n",
    "            resp = run['Resp'].values \n",
    "            onsets = run['StimOnset'].values\n",
    "             \n",
    "            trial_shift = trialtype[1:] #shift TrialType back and insert dummy (-1) in last index\n",
    "            trial_shift = np.append(trial_shift, -1)\n",
    "            correct_shift = correct[1:] #shift Correct back and insert dummy (-1) in last index\n",
    "            correct_shift = np.append(correct_shift, -1)\n",
    "                       \n",
    "            #grab indices matching multiple specified criteria\n",
    "            all_before_B_corr = np.where(((trial_shift=='B')&(correct_shift==1)&(correct==1))&(trialtype!='BL'))[0]\n",
    "            all_before_B_incorr = np.where(((trial_shift=='B')&(correct_shift==0)&(correct==1))&(trialtype!='BL'))[0]  \n",
    "            all_remaining = np.where((correct!=1)&((trialtype=='A')|(trialtype=='C'))|((trial_shift!='B'))|((trialtype=='BL')))[0]\n",
    "\n",
    "            #index onsets array using indices from np.where() criteria \n",
    "            all_before_B_corr_onsets = onsets[all_before_B_corr] \n",
    "            all_before_B_incorr_onsets = onsets[all_before_B_incorr] \n",
    "            all_remaining_onsets = onsets[all_remaining]\n",
    "       \n",
    "            #v-stack matrix containing *ALL* onsets, durations, and amplitudes in vertical columns \n",
    "            mtrx = np.vstack((onsets, np.ones(len(onsets))*2.5, #numpy array filled with 3's\n",
    "                              np.ones(len(onsets)))).T #numpy array filled with 1's\n",
    "            all_before_B_corr_mtrx = np.vstack((all_before_B_corr_onsets, \n",
    "                                                np.ones(len(all_before_B_corr_onsets))*2.5,\n",
    "                                                np.ones(len(all_before_B_corr_onsets)))).T \n",
    "            all_before_B_incorr_mtrx = np.vstack((all_before_B_incorr_onsets,\n",
    "                                                  np.ones(len(all_before_B_incorr_onsets))*2.5,\n",
    "                                                  np.ones(len(all_before_B_incorr_onsets)))).T\n",
    "            all_remaining_mtrx = np.vstack((all_remaining_onsets,\n",
    "                                            np.ones(len(all_remaining_onsets))*2.5,\n",
    "                                            np.ones(len(all_remaining_onsets)))).T\n",
    "            \n",
    "            if not os.path.exists(join(sub_dir, 'model_GLM1.2/')): #if directory does not exist\n",
    "                os.makedirs(join(sub_dir, 'model_GLM1.2/')) #create it\n",
    "\n",
    "            if curr_run == '1': #if the first run in a stimulus set\n",
    "                np.savetxt(sub_dir+'model_GLM1.2/'+'run{0}.txt'.format(i*2+1),mtrx,delimiter='\\t',fmt='%.4f')                \n",
    "                for trial in ['all_before_B_corr', 'all_before_B_incorr', 'all_remaining']: #for all trial types\n",
    "                    exec('np.savetxt(sub_dir+\"model_GLM1.2/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+1,trial))\n",
    "\n",
    "            else: #if the second run in a stimulus set\n",
    "                np.savetxt(sub_dir+'model_GLM1.2/'+'run{0}.txt'.format(i*2+2),mtrx,delimiter='\\t',fmt='%.4f')                \n",
    "                for trial in ['all_before_B_corr', 'all_before_B_incorr', 'all_remaining']:\n",
    "                    exec('np.savetxt(sub_dir+\"model_GLM1.2/\"+\"run{0}_{1}.txt\",{1}_mtrx,delimiter=\"\\t\",fmt=\"%.4f\")'.format(i*2+2,trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
