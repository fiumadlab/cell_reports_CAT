{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model LSS\n",
    "## Isolating trials of learning -- positive derivative value, negative derivative value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMAZE_001\n",
      "WMAZE_002\n",
      "WMAZE_004\n",
      "WMAZE_005\n",
      "WMAZE_006\n",
      "WMAZE_007\n",
      "WMAZE_008\n",
      "WMAZE_009\n",
      "WMAZE_010\n",
      "WMAZE_012\n",
      "WMAZE_017\n",
      "WMAZE_018\n",
      "WMAZE_019\n",
      "WMAZE_020\n",
      "WMAZE_021\n",
      "WMAZE_022\n",
      "WMAZE_023\n",
      "WMAZE_024\n",
      "WMAZE_026\n",
      "WMAZE_027\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from pylab import *\n",
    "import shutil \n",
    "import os\n",
    "from os.path import join, split, basename\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def onset_sort(x):\n",
    "    x = x.split('_')[-1]\n",
    "    return(x[5:-8])\n",
    "\n",
    "#subs = ['WMAZE_001']\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',\n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "sets = ['set1', 'set2', 'set3']\n",
    "runs = ['run1', 'run2', 'run3', 'run4', 'run5', 'run6']\n",
    "\n",
    "for sub in subs:\n",
    "    print sub\n",
    "    sub_dir = '/home/data/madlab/data/mri/wmaze/'  \n",
    "    behav_runs = sorted(glob(join(sub_dir, 'scanner_behav/{0}/{0}_wmazebl_2015*.txt'.format(sub))))\n",
    "    frst_deriv_files = sorted(glob(join(sub_dir,'scanner_behav/{0}/Bprime_pmode_set*.txt'.format(sub))))   \n",
    "    learning_files = sorted(glob(join(sub_dir,'scanner_behav/{0}/B_pmode_set*.txt'.format(sub))))  \n",
    "    upper_95_files = sorted(glob(join(sub_dir,'scanner_behav/{0}/B_p95_set*.txt'.format(sub))))\n",
    "    cope_files = glob(join(sub_dir, 'frstlvl/model_LSS2/{0}/modelfit/contrasts/'.format(sub),\n",
    "                                  '_estimate_model*/cope*_FX_before_COND_*corr_run*_trl*.nii.gz'))\n",
    "        \n",
    "    if not os.path.exists(join(sub_dir, 'frstlvl/model_LSS2/{0}/deriv/'.format(sub))): \n",
    "        os.makedirs(sub_dir + 'frstlvl/model_LSS2/{0}/deriv/learn/'.format(sub))   \n",
    "        os.makedirs(sub_dir + 'frstlvl/model_LSS2/{0}/deriv/nonlearn/'.format(sub))\n",
    "       \n",
    "    #### LOADING AND ORGANIZING THE COPE FILES ####\n",
    "    all_runs = []\n",
    "    for curr_run in runs:\n",
    "        #selects only the cope files containing the current run's number\n",
    "        curr_run_files = np.array([f for f in cope_files if curr_run in f])\n",
    "        #gets the onset time out of the file names using function\n",
    "        onset_nums = [float(onset_sort(f)) for f in curr_run_files] \n",
    "        sorted_nums = np.argsort(onset_nums)\n",
    "        #arranges the actual files according to onset time\n",
    "        curr_run_files = curr_run_files[sorted_nums]\n",
    "        all_runs.append(curr_run_files)\n",
    "           \n",
    "    for i, curr_set in enumerate(sets):\n",
    "        #load derivative, learning, and p95 files\n",
    "        deriv_file = np.loadtxt(frst_deriv_files[i])\n",
    "        learning_curve = np.loadtxt(learning_files[i]) \n",
    "        upper_95 = np.loadtxt(upper_95_files[i])\n",
    "        \n",
    "        #### COPE FILES ####\n",
    "        #merge the two runs into one array for the current stim set\n",
    "        curr_set_copes = np.concatenate((all_runs[i*2], all_runs[i*2+1])) \n",
    "        \n",
    "        #### GETTING THE DERIV FILES TO MATCH NUMBER OF COPES ####\n",
    "        #load behavioral files\n",
    "        behav_run1 = pd.read_table(behav_runs[i*2])\n",
    "        behav_run2 = pd.read_table(behav_runs[i*2+1])\n",
    "        \n",
    "        #info concerning onset time\n",
    "        behav_os = np.empty(320, dtype=object)\n",
    "        behav_os[:160] = behav_run1['StimOnset'].values\n",
    "        behav_os[160:] = behav_run2['StimOnset'].values\n",
    "        \n",
    "        #info concerning subject response\n",
    "        behav_resp = np.empty(320, dtype=object)\n",
    "        behav_resp[:160] = behav_run1['Resp'].values\n",
    "        behav_resp[160:] = behav_run2['Resp'].values\n",
    "        \n",
    "        #info concerning trial type\n",
    "        behav_type = np.empty(320, dtype=object)\n",
    "        behav_type[:160] = behav_run1['TrialType'].values\n",
    "        behav_type[160:] = behav_run2['TrialType'].values\n",
    "        \n",
    "        trial_shift = behav_type[:-1] \n",
    "        trial_shift = np.insert(trial_shift, 0, -1)\n",
    "        \n",
    "        #indices of all Bs in the original dataset without preceeding BL trials\n",
    "        b_indices = np.where((behav_type == 'B'))[0]\n",
    "        #grabs B trials with preceeding BLs\n",
    "        b_BL_indices = np.where((behav_type == 'B') & (trial_shift == 'BL'))[0]       \n",
    "        \n",
    "        #isolate bad Bs for removal in learning curve/derivative/p95 files\n",
    "        bad_Bs = [] \n",
    "        bad_Bs.extend(b_BL_indices)\n",
    "        for curr_B in b_indices:\n",
    "            if not curr_B in bad_Bs:               \n",
    "                if behav_resp[curr_B] == 'NR': #identify in B trials which are non-response\n",
    "                    bad_Bs.append(curr_B)\n",
    "                #indices if B trial comes first (observed on 001 run 6)    \n",
    "                if curr_B in [0, 157, 158, 159, 160, 317, 318, 319]: \n",
    "                    bad_Bs.append(curr_B)\n",
    "        bad_Bs.sort() \n",
    "        \n",
    "        #get the indices for the bad Bs within the group of Bs\n",
    "        bad_B_ind = [j for j, f in enumerate(b_indices) if f in bad_Bs] \n",
    "        bad_B_ind.sort()\n",
    "        #reverse order of Bs to be removed\n",
    "        bad_B_ind = bad_B_ind[::-1] \n",
    "                      \n",
    "        #LEARNING CURVE FILES\n",
    "        #create a temp version of learning_curve\n",
    "        temp2 = list(learning_curve)\n",
    "        #pop out the bad Bs starting from the end\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp2.pop(curr_bad_B)\n",
    "        #save without the removed Bs    \n",
    "        new_learning = np.array(temp2)        \n",
    "        \n",
    "        #P95 FILES\n",
    "        temp3 = list(upper_95)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp3.pop(curr_bad_B)  \n",
    "        # new upper 95% without bad Bs    \n",
    "        new_upper_95 = np.array(temp3)\n",
    "                \n",
    "        #DERIV FILES\n",
    "        temp = list(deriv_file)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp.pop(curr_bad_B)   \n",
    "        new_deriv = np.array(temp[:-1])\n",
    "        learning = np.where(new_deriv > 0)[0]\n",
    "        nonlearning = np.where(new_deriv <= 0)[0]         \n",
    "            \n",
    "        #remove the bad Bs from the B-list\n",
    "        temp4 = list(b_indices)\n",
    "        for curr_bad_B in bad_B_ind:\n",
    "            temp4.pop(curr_bad_B)\n",
    "        good_Bs = np.array(temp4)\n",
    "       \n",
    "        #convert original behavioral file indices to new B-specific index\n",
    "        new_indices_B = []\n",
    "        for n, curr_new_B in enumerate(good_Bs):\n",
    "            new_indices_B.append(n)\n",
    "        new_indices_B = np.array(new_indices_B)\n",
    "        #grabs the B trials with a positive value derivative\n",
    "        b_learning = new_indices_B[learning]\n",
    "        b_nonlearning = new_indices_B[nonlearning]\n",
    "        fixed_learning_files = curr_set_copes[b_learning]\n",
    "        fixed_nonlearning_files = curr_set_copes[b_nonlearning]                \n",
    "                      \n",
    "        #copy and save selected learning files to new folder for merge script\n",
    "        for curr_learning in fixed_learning_files:\n",
    "            learn_base =  os.path.basename(curr_learning)  \n",
    "            shutil.copy2(curr_learning,\n",
    "                         join(sub_dir,'frstlvl/model_LSS2/{0}/deriv/learn/{1}'.format(sub,learn_base)))\n",
    "        #copy and save selected after files to new folder for merge script   \n",
    "        for curr_nonlearning in fixed_nonlearning_files:\n",
    "            nonlearn_base =  os.path.basename(curr_nonlearning)\n",
    "            shutil.copy2(curr_nonlearning,\n",
    "                         join(sub_dir,'frstlvl/model_LSS2/{0}/deriv/nonlearn/{1}'.format(sub,nonlearn_base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
