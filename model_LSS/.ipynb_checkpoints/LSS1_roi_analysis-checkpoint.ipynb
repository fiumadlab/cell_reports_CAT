{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL LSS1\n",
    "### Compares positive derivative to negative derivatives\n",
    "### Contains only fixed-before-conditional trials without intervening BLs\n",
    "### Combines A & C trials into single regressor\n",
    "## Regions of interest:\n",
    "### Hippocampus (FS labels: hippocampus [17, 53])\n",
    "### Dorsal caudate (hand-drawn by Mandy)\n",
    "### Medial PFC (Lausanne labels: \n",
    "####      LH -  [1002,1014,1026,1028,1032,1159,1172,1173,1174],\n",
    "####      RH - [2002,2014,2026,2028,2032,2159,2172,2173,2174])\n",
    "### Dorsolateral PFC (Lausanne atlas: dlPFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from glob import glob\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from math import sqrt\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette('muted')\n",
    "\n",
    "subs = ['WMAZE_001', 'WMAZE_002', 'WMAZE_004', 'WMAZE_005', 'WMAZE_006',\n",
    "        'WMAZE_007', 'WMAZE_008', 'WMAZE_009', 'WMAZE_010', 'WMAZE_012',\n",
    "        'WMAZE_017', 'WMAZE_018', 'WMAZE_019', 'WMAZE_020', 'WMAZE_021',  \n",
    "        'WMAZE_022', 'WMAZE_023', 'WMAZE_024', 'WMAZE_026', 'WMAZE_027']\n",
    "\n",
    "proj_dir = '/home/data/madlab/data/mri/wmaze' \n",
    "mask_files = []\n",
    "cope_files = []\n",
    "\n",
    "for sub in subs:\n",
    "    mask_glob = glob(proj_dir + '/roi_analysis/model3_betaseries/mask/anat_masks/_subject_id_' \n",
    "                     + sub + '/_anatmask_xfm*/*')\n",
    "    mask_files.append(sorted(mask_glob))\n",
    "    copes_glob = glob(proj_dir + '/frstlvl/wmaze_MRthesis/fixed_before_conditional/model3_2-3-2-5/merge_copes/'\n",
    "                      + sub + '/merged/cope_*')\n",
    "    cope_files.append(sorted(copes_glob))\n",
    "    if len(cope_files[-1]) == 0:\n",
    "        print(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell to double-check the array indexing for both the masks and the copes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#change first index of cope_files to indicate participant index in sids array\n",
    "for i, curr_mask in enumerate(mask_files[0]):\n",
    "    print(i, mask_files[0][i].split('/')[-1][:-7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, curr_cope in enumerate(cope_files[0]):\n",
    "    print(i, cope_files[0][i].split('/')[-1][5:-7]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use binarized mask to obtain activation in left & right hemisphere for each ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = {'subjid':[],\n",
    "            'lhhp_nonlearn':[], 'rhhp_nonlearn':[], 'lhhp_learn':[], 'rhhp_learn':[],\n",
    "            'lhcaud_nonlearn':[], 'rhcaud_nonlearn':[], 'lhcaud_learn':[], 'rhcaud_learn':[],\n",
    "            'lhdlpfc_nonlearn':[], 'rhdlpfc_nonlearn':[], 'lhdlpfc_learn':[], 'rhdlpfc_learn':[],\n",
    "            'lhmpfc_nonlearn':[], 'rhmpfc_nonlearn':[], 'lhmpfc_learn':[], 'rhmpfc_learn':[],\n",
    "            'lhput_nonlearn':[], 'rhput_nonlearn':[], 'lhput_learn':[], 'rhput_learn':[],\n",
    "            'lhmotor_nonlearn':[], 'rhmotor_nonlearn':[], 'lhmotor_learn':[], 'rhmotor_learn':[]}\n",
    "\n",
    "corr_matrix = np.zeros((len(subs), 7)) \n",
    "\n",
    "for i in range(len(subs)):\n",
    "    all_data['subjid'].append(subs[i])\n",
    "    #ROI masks\n",
    "    lh_hp_img = nb.load(mask_files[i][1])\n",
    "    rh_hp_img = nb.load(mask_files[i][10])\n",
    "    lh_mpfc_img = nb.load(mask_files[i][18])\n",
    "    rh_mpfc_img = nb.load(mask_files[i][19])\n",
    "    lh_caud_img = nb.load(mask_files[i][8])\n",
    "    rh_caud_img = nb.load(mask_files[i][13]) \n",
    "    lh_dlpfc_img = nb.load(mask_files[i][0])\n",
    "    rh_dlpfc_img = nb.load(mask_files[i][9])    \n",
    "    lh_put_img = nb.load(mask_files[i][7])\n",
    "    rh_put_img = nb.load(mask_files[i][12])    \n",
    "    lh_motor_img = nb.load(mask_files[i][6])\n",
    "    rh_motor_img = nb.load(mask_files[i][17]) \n",
    "    #copes\n",
    "    learn_img = nb.load(cope_files[i][0])\n",
    "    nonlearn_img = nb.load(cope_files[i][1])   \n",
    "  \n",
    "    region = ['hp', 'mpfc', 'caud', 'dlpfc', 'put', 'motor']\n",
    "    learn_type = ['learn', 'nonlearn']   \n",
    "    for r in region: #iterate by region and learn_type to get cope voxels only in masked region\n",
    "        for l in learn_type:\n",
    "            lh_data = eval('{0}_img.get_data()[lh_{1}_img.get_data() > 0.]'.format(l,r))\n",
    "            all_data['lh{0}_{1}'.format(r,l)].append(lh_data[0:-1])          \n",
    "            rh_data = eval('{0}_img.get_data()[rh_{1}_img.get_data() > 0.]'.format(l,r))\n",
    "            all_data['rh{0}_{1}'.format(r,l)].append(rh_data[0:-1])\n",
    "            \n",
    "    #all keys to be combined into bihemispheric masks\n",
    "    all_keys = ['lhhp_nonlearn', 'rhhp_nonlearn', 'lhhp_learn', 'rhhp_learn',        \n",
    "                'lhcaud_nonlearn', 'rhcaud_nonlearn', 'lhcaud_learn', 'rhcaud_learn', \n",
    "                'lhput_nonlearn', 'rhput_nonlearn', 'lhput_learn', 'rhput_learn', \n",
    "                'lhdlpfc_nonlearn', 'rhdlpfc_nonlearn', 'lhdlpfc_learn', 'rhdlpfc_learn',\n",
    "                'lhmpfc_nonlearn', 'rhmpfc_nonlearn', 'lhmpfc_learn', 'rhmpfc_learn',\n",
    "                'lhmotor_nonlearn', 'rhmotor_nonlearn', 'lhmotor_learn', 'rhmotor_learn']\n",
    "            \n",
    "    for key in all_keys: #averaging each column for only current participant \n",
    "        all_data[key][-1] = np.mean(all_data[key][-1],axis=0) \n",
    "        \n",
    "    for r in region: #combine two hemispheres into single mask\n",
    "        for l in learn_type:\n",
    "            all_data['{0}_{1}'.format(r,l)] = (np.array(all_data['lh{0}_{1}'.format(r,l)][-1])\n",
    "                                               +np.array(all_data['rh{0}_{1}'.format(r,l)][-1]))/2\n",
    "                \n",
    "    corr_matrix[i][0] = float(subs[i][-3:]) #creation of correlation matrix\n",
    "    corr_matrix[i][1] = stats.pearsonr(all_data['hp_learn'], all_data['mpfc_learn'])[0]\n",
    "    corr_matrix[i][2] = stats.pearsonr(all_data['hp_nonlearn'], all_data['mpfc_nonlearn'])[0]\n",
    "    corr_matrix[i][3] = stats.pearsonr(all_data['caud_learn'], all_data['dlpfc_learn'])[0]\n",
    "    corr_matrix[i][4] = stats.pearsonr(all_data['caud_nonlearn'], all_data['dlpfc_nonlearn'])[0]\n",
    "    corr_matrix[i][5] = stats.pearsonr(all_data['put_learn'], all_data['motor_learn'])[0]\n",
    "    corr_matrix[i][6] = stats.pearsonr(all_data['put_nonlearn'], all_data['motor_nonlearn'])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_plot = {} #create Pandas dataframe to store correlations\n",
    "corr_plot['hp-mpfc_learn'] = corr_matrix[:, 1] \n",
    "corr_plot['hp-mpfc_nonlearn'] = corr_matrix[:, 2] \n",
    "corr_plot['caud-dlpfc_learn'] = corr_matrix[:, 3] \n",
    "corr_plot['caud-dlpfc_nonlearn'] = corr_matrix[:, 4] \n",
    "corr_plot['put-motor_learn'] = corr_matrix[:, 5] \n",
    "corr_plot['put-motor_nonlearn'] = corr_matrix[:, 6] \n",
    "corr_plot_df = pd.DataFrame.from_dict(corr_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#corr_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in corr_plot_df: #get mean and std of correlations for each regional pair\n",
    "    print \"Mean {0}: \".format(key), np.mean(corr_plot_df['{0}'.format(key)])\n",
    "    print \"STD {0}: \".format(key), np.std(corr_plot_df['{0}'.format(key)])\n",
    "    print \"\"    \n",
    "N = 6\n",
    "conditions = ['HPC-mPFC_learn', 'HPC-mPFC_nonlearn', \n",
    "              'Caud-dlPFC_learn', 'Caud-dlPFC_nonlearn',\n",
    "              'Put-Motor_learn', 'Put-Motor_nonlearn']\n",
    "allsubjs = [corr_plot['hp-mpfc_learn'], corr_plot['hp-mpfc_nonlearn'],\n",
    "            corr_plot['caud-dlpfc_learn'], corr_plot['caud-dlpfc_nonlearn'],\n",
    "            corr_plot['put-motor_learn'], corr_plot['put-motor_nonlearn']]\n",
    "ind = np.arange(N)\n",
    "fig, ax = plt.subplots(figsize = (12,6)) #large plot to represent all pairs\n",
    "ax = sns.boxplot(data = allsubjs, width = 0.3)\n",
    "ax = sns.swarmplot(data = allsubjs, color='.25')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_ylabel(\"Correlation (r)\")\n",
    "ax.set_title(\"Regional Coactivation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohens_d = ((np.average(corr_plot['hp-mpfc_learn']) - np.average(corr_plot['hp-mpfc_nonlearn'])) \n",
    "            / (sqrt((np.std(corr_plot['hp-mpfc_learn'], ddof = 1)) ** 2 \n",
    "            + np.std(corr_plot['hp-mpfc_nonlearn'], ddof = 1) ** 2) / 2))\n",
    "print 'Learn Norm Test', stats.normaltest(corr_plot['hp-mpfc_learn'])[:]\n",
    "print 'Nonlearn Norm Test', stats.normaltest(corr_plot['hp-mpfc_nonlearn'])[:]\n",
    "print 'T-test:', stats.ttest_rel(corr_plot['hp-mpfc_learn'],corr_plot['hp-mpfc_nonlearn'])[:]\n",
    "print \"Cohen's d =\", cohens_d\n",
    "N = 2\n",
    "conditions = ['HPC-mPFC Learn', 'HPC-mPFC Nonlearn']\n",
    "allsubjs = [corr_plot['hp-mpfc_learn'], corr_plot['hp-mpfc_nonlearn']]\n",
    "ind = np.arange(N)   \n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax = sns.boxplot(data = allsubjs, width = 0.3)\n",
    "ax = sns.swarmplot(data = allsubjs, color = '.25')\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_title(\"HPC-mPFC Coactivation\")\n",
    "ax.set_ylabel(\"Correlation (r)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohens_d = ((np.average(corr_plot['caud-dlpfc_learn']) - np.average(corr_plot['caud-dlpfc_nonlearn'])) \n",
    "            / (sqrt((np.std(corr_plot['caud-dlpfc_learn'], ddof = 1)) ** 2 \n",
    "            + np.std(corr_plot['caud-dlpfc_nonlearn'], ddof = 1) ** 2) / 2))\n",
    "print 'Learn Norm Test', stats.normaltest(corr_plot['caud-dlpfc_learn'])[:]\n",
    "print 'Nonlearn Norm Test', stats.normaltest(corr_plot['caud-dlpfc_nonlearn'])[:]\n",
    "print 'T-test:', stats.ttest_rel(corr_plot['caud-dlpfc_learn'],corr_plot['caud-dlpfc_nonlearn'])[:]\n",
    "print \"Cohen's d =\", cohens_d\n",
    "N = 2\n",
    "conditions = ['Caud-dlPFC Learn', 'Caud-dlPFC Nonlearn']\n",
    "allsubjs = [corr_plot['caud-dlpfc_learn'], corr_plot['caud-dlpfc_nonlearn']]\n",
    "ind = np.arange(N)   \n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax = sns.boxplot(data = allsubjs, width = 0.3)\n",
    "ax = sns.swarmplot(data = allsubjs, color = '.25')\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_title(\"Caud-dlPFC Coactivation\")\n",
    "ax.set_ylabel(\"Correlation (r)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohens_d = ((np.average(corr_plot['put-motor_learn']) - np.average(corr_plot['put-motor_nonlearn'])) \n",
    "            / (sqrt((np.std(corr_plot['put-motor_learn'], ddof = 1)) ** 2 \n",
    "            + np.std(corr_plot['put-motor_nonlearn'], ddof = 1) ** 2) / 2))\n",
    "print 'Learn Norm Test', stats.normaltest(corr_plot['put-motor_learn'])[:]\n",
    "print 'Nonlearn Norm Test', stats.normaltest(corr_plot['put-motor_nonlearn'])[:]\n",
    "print 'T-test:', stats.ttest_rel(corr_plot['put-motor_learn'],corr_plot['put-motor_nonlearn'])[:]\n",
    "print \"Cohen's d =\", cohens_d\n",
    "N = 2\n",
    "conditions = ['Put-Motor Learn', 'Put-Motor Nonlearn']\n",
    "allsubjs = [corr_plot['put-motor_learn'], corr_plot['put-motor_nonlearn']]\n",
    "ind = np.arange(N)   \n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax = sns.boxplot(data = allsubjs, width = 0.3)\n",
    "ax = sns.swarmplot(data = allsubjs, color = '.25')\n",
    "ax.set_xticklabels(conditions)\n",
    "ax.set_title(\"Put-Motor Coactivation\")\n",
    "ax.set_ylabel(\"Correlation (r)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in ['learn', 'nonlearn']:\n",
    "    x = [i for i in range(0,len(all_data['hp_{0}'.format(l)]),1)]\n",
    "    y = all_data['hp_{0}'.format(l)]\n",
    "    z = all_data['mpfc_{0}'.format(l)]\n",
    "    print \"{0}ing coactivation:\".format(l), stats.pearsonr(all_data['hp_{0}'.format(l)], all_data['mpfc_{0}'.format(l)])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (11, 4), sharex = True, sharey = True)\n",
    "    ax1.plot(x, y, color = 'blue')\n",
    "    ax1.set_ylabel('Activation')\n",
    "    ax1.set_xlabel('Trials')\n",
    "    ax1.set_title('HPC activation - {0}ing'.format(l))\n",
    "    ax2.plot(x, z, color = 'purple')\n",
    "    ax2.set_xlabel('Trials')\n",
    "    ax2.set_title('mPFC activation - {0}ing'.format(l))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in ['learn', 'nonlearn']:\n",
    "    x = [i for i in range(0,len(all_data['caud_{0}'.format(l)]),1)]\n",
    "    y = all_data['caud_{0}'.format(l)]\n",
    "    z = all_data['dlpfc_{0}'.format(l)]\n",
    "    print \"{0}ing coactivation:\".format(l), stats.pearsonr(all_data['caud_{0}'.format(l)], all_data['dlpfc_{0}'.format(l)])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (11, 4), sharex = True, sharey = True)\n",
    "    ax1.plot(x, y, color = 'blue')\n",
    "    ax1.set_ylabel('Activation')\n",
    "    ax1.set_xlabel('Trials')\n",
    "    ax1.set_title('Caudate activation - {0}ing'.format(l))\n",
    "    ax2.plot(x, z, color = 'purple')\n",
    "    ax2.set_xlabel('Trials')\n",
    "    ax2.set_title('dlPFC activation - {0}ing'.format(l))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in ['learn', 'nonlearn']:\n",
    "    x = [i for i in range(0,len(all_data['put_{0}'.format(l)]),1)]\n",
    "    y = all_data['put_{0}'.format(l)]\n",
    "    z = all_data['motor_{0}'.format(l)]\n",
    "    print \"{0}ing coactivation:\".format(l), stats.pearsonr(all_data['put_{0}'.format(l)], all_data['motor_{0}'.format(l)])\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (11, 4), sharex = True, sharey = True)\n",
    "    ax1.plot(x, y, color = 'blue')\n",
    "    ax1.set_ylabel('Activation')\n",
    "    ax1.set_xlabel('Trials')\n",
    "    ax1.set_title('Putamen activation - {0}ing'.format(l))\n",
    "    ax2.plot(x, z, color = 'purple')\n",
    "    ax2.set_xlabel('Trials')\n",
    "    ax2.set_title('Motor activation - {0}ing'.format(l))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
